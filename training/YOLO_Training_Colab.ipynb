{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOLO Tree Detection Training - Vineyard Robot\n",
    "\n",
    "This notebook trains a YOLOv8 model to detect:\n",
    "- **Vineyard**: trunk, canopy, grape clusters\n",
    "- **Tangerine**: trunk, canopy, fruit\n",
    "\n",
    "## Steps:\n",
    "1. Install dependencies\n",
    "2. Upload and organize your labeled images\n",
    "3. Train the model\n",
    "4. Download trained weights for Raspberry Pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Install YOLOv8 (Ultralytics)\n",
    "!pip install ultralytics\n",
    "!pip install roboflow  # Optional: for easier dataset management\n",
    "\n",
    "from ultralytics import YOLO\n",
    "import os\n",
    "import shutil\n",
    "from google.colab import files, drive\n",
    "import yaml\n",
    "\n",
    "print(\"Ultralytics installed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Mount Google Drive (to access your photo folders)\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Check your folders - update these paths to match your Drive structure\n",
    "# Example: /content/drive/MyDrive/TreePhotos/vineyard\n",
    "#          /content/drive/MyDrive/TreePhotos/tangerine\n",
    "\n",
    "print(\"\\nLooking for image folders...\")\n",
    "!ls -la /content/drive/MyDrive/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Configure your dataset\n",
    "# ================================\n",
    "# EDIT THESE SETTINGS:\n",
    "\n",
    "# Choose which tree type to train\n",
    "TREE_TYPE = \"vineyard\"  # or \"tangerine\"\n",
    "\n",
    "# Path to your images in Google Drive\n",
    "# These should be folders containing your photos\n",
    "IMAGES_PATH = f\"/content/drive/MyDrive/TreePhotos/{TREE_TYPE}\"\n",
    "\n",
    "# Classes to detect (adjust based on your tree type)\n",
    "if TREE_TYPE == \"vineyard\":\n",
    "    CLASSES = ['vineyard_trunk', 'vineyard_canopy', 'grape_cluster', 'post']\n",
    "elif TREE_TYPE == \"tangerine\":\n",
    "    CLASSES = ['tangerine_trunk', 'tangerine_canopy', 'tangerine_fruit', 'post']\n",
    "else:\n",
    "    CLASSES = ['trunk', 'canopy', 'fruit', 'post']\n",
    "\n",
    "print(f\"Training for: {TREE_TYPE}\")\n",
    "print(f\"Classes: {CLASSES}\")\n",
    "print(f\"Images path: {IMAGES_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option A: Use Roboflow for Easy Labeling (Recommended)\n",
    "\n",
    "1. Go to [Roboflow](https://roboflow.com) and create a free account\n",
    "2. Create a new project and upload your images\n",
    "3. Label images by drawing bounding boxes around trunks, canopy, fruit\n",
    "4. Export as \"YOLOv8\" format and get the download code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4A: Download dataset from Roboflow (if using Roboflow)\n",
    "# Uncomment and paste your Roboflow export code here:\n",
    "\n",
    "# from roboflow import Roboflow\n",
    "# rf = Roboflow(api_key=\"YOUR_API_KEY\")\n",
    "# project = rf.workspace(\"your-workspace\").project(\"your-project\")\n",
    "# dataset = project.version(1).download(\"yolov8\")\n",
    "# DATASET_PATH = dataset.location\n",
    "\n",
    "print(\"Uncomment the code above and paste your Roboflow export code\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option B: Manual Labeling with LabelImg\n",
    "\n",
    "If you've already labeled images with LabelImg:\n",
    "1. Your images should be in a folder with corresponding `.txt` annotation files\n",
    "2. Each `.txt` file has format: `class_id x_center y_center width height` (normalized 0-1)\n",
    "3. Upload them to Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4B: Setup dataset from manually labeled images\n",
    "\n",
    "# Create dataset directory structure\n",
    "DATASET_PATH = \"/content/dataset\"\n",
    "os.makedirs(f\"{DATASET_PATH}/images/train\", exist_ok=True)\n",
    "os.makedirs(f\"{DATASET_PATH}/images/val\", exist_ok=True)\n",
    "os.makedirs(f\"{DATASET_PATH}/labels/train\", exist_ok=True)\n",
    "os.makedirs(f\"{DATASET_PATH}/labels/val\", exist_ok=True)\n",
    "\n",
    "# Path to your labeled images and annotations in Drive\n",
    "# Images: .jpg, .png files\n",
    "# Labels: .txt files with same name as images\n",
    "\n",
    "SOURCE_IMAGES = f\"/content/drive/MyDrive/TreePhotos/{TREE_TYPE}/images\"\n",
    "SOURCE_LABELS = f\"/content/drive/MyDrive/TreePhotos/{TREE_TYPE}/labels\"\n",
    "\n",
    "# Check if paths exist\n",
    "print(f\"Looking for images in: {SOURCE_IMAGES}\")\n",
    "print(f\"Looking for labels in: {SOURCE_LABELS}\")\n",
    "\n",
    "if os.path.exists(SOURCE_IMAGES):\n",
    "    images = [f for f in os.listdir(SOURCE_IMAGES) if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
    "    print(f\"Found {len(images)} images\")\n",
    "else:\n",
    "    print(\"Images folder not found! Update SOURCE_IMAGES path.\")\n",
    "    images = []\n",
    "\n",
    "if os.path.exists(SOURCE_LABELS):\n",
    "    labels = [f for f in os.listdir(SOURCE_LABELS) if f.endswith('.txt')]\n",
    "    print(f\"Found {len(labels)} label files\")\n",
    "else:\n",
    "    print(\"Labels folder not found! Update SOURCE_LABELS path.\")\n",
    "    labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Split data into train/val and copy to dataset folder\n",
    "import random\n",
    "\n",
    "if images:\n",
    "    # Shuffle and split 80/20\n",
    "    random.shuffle(images)\n",
    "    split_idx = int(len(images) * 0.8)\n",
    "    train_images = images[:split_idx]\n",
    "    val_images = images[split_idx:]\n",
    "\n",
    "    print(f\"Train: {len(train_images)} images\")\n",
    "    print(f\"Val: {len(val_images)} images\")\n",
    "\n",
    "    # Copy files\n",
    "    for img in train_images:\n",
    "        shutil.copy(f\"{SOURCE_IMAGES}/{img}\", f\"{DATASET_PATH}/images/train/{img}\")\n",
    "        label = img.rsplit('.', 1)[0] + '.txt'\n",
    "        if os.path.exists(f\"{SOURCE_LABELS}/{label}\"):\n",
    "            shutil.copy(f\"{SOURCE_LABELS}/{label}\", f\"{DATASET_PATH}/labels/train/{label}\")\n",
    "\n",
    "    for img in val_images:\n",
    "        shutil.copy(f\"{SOURCE_IMAGES}/{img}\", f\"{DATASET_PATH}/images/val/{img}\")\n",
    "        label = img.rsplit('.', 1)[0] + '.txt'\n",
    "        if os.path.exists(f\"{SOURCE_LABELS}/{label}\"):\n",
    "            shutil.copy(f\"{SOURCE_LABELS}/{label}\", f\"{DATASET_PATH}/labels/val/{label}\")\n",
    "\n",
    "    print(\"\\nDataset prepared!\")\n",
    "else:\n",
    "    print(\"No images found. Please check your paths.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Create dataset.yaml config file\n",
    "\n",
    "dataset_config = {\n",
    "    'path': DATASET_PATH,\n",
    "    'train': 'images/train',\n",
    "    'val': 'images/val',\n",
    "    'names': {i: name for i, name in enumerate(CLASSES)}\n",
    "}\n",
    "\n",
    "yaml_path = f\"{DATASET_PATH}/dataset.yaml\"\n",
    "with open(yaml_path, 'w') as f:\n",
    "    yaml.dump(dataset_config, f, default_flow_style=False)\n",
    "\n",
    "print(f\"Created {yaml_path}:\")\n",
    "print(\"=\"*40)\n",
    "with open(yaml_path, 'r') as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## If You Haven't Labeled Yet - Quick Labeling Guide\n",
    "\n",
    "Use this cell to set up labeling with LabelImg directly in Colab:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Create a classes.txt file for LabelImg\n",
    "# Download this and use it when labeling locally with LabelImg\n",
    "\n",
    "classes_txt = \"\\n\".join(CLASSES)\n",
    "with open('/content/classes.txt', 'w') as f:\n",
    "    f.write(classes_txt)\n",
    "\n",
    "print(\"Classes for labeling:\")\n",
    "print(\"=\"*40)\n",
    "for i, c in enumerate(CLASSES):\n",
    "    print(f\"  {i}: {c}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*40)\n",
    "print(\"LABELING INSTRUCTIONS:\")\n",
    "print(\"=\"*40)\n",
    "print(\"1. Download LabelImg: pip install labelImg\")\n",
    "print(\"2. Run: labelImg\")\n",
    "print(\"3. Open Dir -> select your images folder\")\n",
    "print(\"4. Change Save Dir -> same folder or /labels subfolder\")\n",
    "print(\"5. Use 'YOLO' format (not PascalVOC)\")\n",
    "print(\"6. Draw boxes around: trunks, canopy, fruit, posts\")\n",
    "print(\"7. Press 'w' to draw box, select class, save (Ctrl+S)\")\n",
    "print(\"8. Upload labeled images+txt files to Google Drive\")\n",
    "\n",
    "files.download('/content/classes.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Train YOLOv8 Model\n",
    "# ==========================\n",
    "\n",
    "# Load pretrained YOLOv8 nano model (fastest, good for Raspberry Pi)\n",
    "# Options: yolov8n.pt (nano), yolov8s.pt (small), yolov8m.pt (medium)\n",
    "model = YOLO('yolov8n.pt')  # Using nano for Raspberry Pi speed\n",
    "\n",
    "# Train the model\n",
    "results = model.train(\n",
    "    data=yaml_path,\n",
    "    epochs=100,           # Number of training epochs (adjust as needed)\n",
    "    imgsz=640,            # Image size\n",
    "    batch=16,             # Batch size (reduce if out of memory)\n",
    "    patience=20,          # Early stopping patience\n",
    "    save=True,\n",
    "    project='/content/runs',\n",
    "    name=f'{TREE_TYPE}_detector',\n",
    "    exist_ok=True,\n",
    "    pretrained=True,\n",
    "    optimizer='auto',\n",
    "    verbose=True,\n",
    "    seed=42,\n",
    "    deterministic=True,\n",
    "    single_cls=False,\n",
    "    rect=False,\n",
    "    cos_lr=True,          # Cosine learning rate\n",
    "    close_mosaic=10,      # Disable mosaic last 10 epochs\n",
    "    resume=False,\n",
    "    amp=True,             # Mixed precision training\n",
    "    fraction=1.0,\n",
    "    profile=False,\n",
    "    freeze=None,\n",
    "    lr0=0.01,             # Initial learning rate\n",
    "    lrf=0.01,             # Final learning rate factor\n",
    "    momentum=0.937,\n",
    "    weight_decay=0.0005,\n",
    "    warmup_epochs=3.0,\n",
    "    warmup_momentum=0.8,\n",
    "    warmup_bias_lr=0.1,\n",
    "    box=7.5,              # Box loss gain\n",
    "    cls=0.5,              # Class loss gain\n",
    "    dfl=1.5,              # DFL loss gain\n",
    "    pose=12.0,\n",
    "    kobj=1.0,\n",
    "    label_smoothing=0.0,\n",
    "    nbs=64,\n",
    "    hsv_h=0.015,          # Augmentation: HSV-Hue\n",
    "    hsv_s=0.7,            # Augmentation: HSV-Saturation\n",
    "    hsv_v=0.4,            # Augmentation: HSV-Value\n",
    "    degrees=0.0,          # Rotation\n",
    "    translate=0.1,        # Translation\n",
    "    scale=0.5,            # Scale\n",
    "    shear=0.0,\n",
    "    perspective=0.0,\n",
    "    flipud=0.0,           # Vertical flip\n",
    "    fliplr=0.5,           # Horizontal flip\n",
    "    mosaic=1.0,           # Mosaic augmentation\n",
    "    mixup=0.0,\n",
    "    copy_paste=0.0,\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"TRAINING COMPLETE!\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: View training results\n",
    "from IPython.display import Image, display\n",
    "import glob\n",
    "\n",
    "# Find the latest run\n",
    "run_path = f'/content/runs/{TREE_TYPE}_detector'\n",
    "\n",
    "# Display training curves\n",
    "if os.path.exists(f'{run_path}/results.png'):\n",
    "    display(Image(filename=f'{run_path}/results.png', width=800))\n",
    "\n",
    "# Display confusion matrix\n",
    "if os.path.exists(f'{run_path}/confusion_matrix.png'):\n",
    "    display(Image(filename=f'{run_path}/confusion_matrix.png', width=600))\n",
    "\n",
    "# Display sample predictions\n",
    "val_preds = glob.glob(f'{run_path}/val_batch*_pred.jpg')\n",
    "for pred in val_preds[:3]:\n",
    "    display(Image(filename=pred, width=800))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10: Test the model on a sample image\n",
    "\n",
    "# Load best weights\n",
    "best_model = YOLO(f'{run_path}/weights/best.pt')\n",
    "\n",
    "# Test on a validation image\n",
    "val_images = glob.glob(f'{DATASET_PATH}/images/val/*.jpg')\n",
    "if val_images:\n",
    "    test_img = val_images[0]\n",
    "    results = best_model(test_img)\n",
    "    \n",
    "    # Save and display result\n",
    "    for r in results:\n",
    "        im_array = r.plot()\n",
    "        from PIL import Image as PILImage\n",
    "        im = PILImage.fromarray(im_array[..., ::-1])  # BGR to RGB\n",
    "        im.save('/content/test_result.jpg')\n",
    "    \n",
    "    display(Image(filename='/content/test_result.jpg', width=640))\n",
    "    \n",
    "    # Print detections\n",
    "    for r in results:\n",
    "        for box in r.boxes:\n",
    "            cls = int(box.cls[0])\n",
    "            conf = float(box.conf[0])\n",
    "            print(f\"Detected: {CLASSES[cls]} ({conf:.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 11: Export model for Raspberry Pi\n",
    "# ======================================\n",
    "\n",
    "# Export to ONNX (optional - for faster inference)\n",
    "# best_model.export(format='onnx')\n",
    "\n",
    "# Copy best weights to Drive for easy transfer to Pi\n",
    "output_dir = f\"/content/drive/MyDrive/TreeModels\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Copy best.pt\n",
    "src_weights = f'{run_path}/weights/best.pt'\n",
    "dst_weights = f'{output_dir}/{TREE_TYPE}_best.pt'\n",
    "shutil.copy(src_weights, dst_weights)\n",
    "\n",
    "print(f\"\\nModel saved to Google Drive: {dst_weights}\")\n",
    "print(f\"\\nTo use on Raspberry Pi:\")\n",
    "print(f\"1. Download: {dst_weights}\")\n",
    "print(f\"2. Copy to: /home/pi/Working Code/Updated FULL Code Standalone/models/\")\n",
    "print(f\"3. Update config.py: YOLO_MODEL_PATH = 'models/{TREE_TYPE}_best.pt'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 12: Download model directly (alternative to Drive)\n",
    "\n",
    "# Download the trained weights\n",
    "files.download(f'{run_path}/weights/best.pt')\n",
    "\n",
    "print(\"\\nDownloading best.pt...\")\n",
    "print(\"Rename it to match your TREE_TYPE and copy to Raspberry Pi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Tips\n",
    "\n",
    "### If training is slow:\n",
    "- Use `Runtime > Change runtime type > GPU` (T4 is free)\n",
    "- Reduce `imgsz` to 480 or 320\n",
    "- Reduce `batch` size\n",
    "\n",
    "### If accuracy is low:\n",
    "- Add more training images (aim for 100+ per class)\n",
    "- Make sure labels are accurate (boxes tight around objects)\n",
    "- Increase `epochs` to 200-300\n",
    "- Try `yolov8s.pt` (small) instead of nano\n",
    "\n",
    "### For Raspberry Pi performance:\n",
    "- Use YOLOv8n (nano) - fastest\n",
    "- Use `imgsz=320` during inference\n",
    "- Consider ONNX export for speed boost\n",
    "\n",
    "### Class labeling guide:\n",
    "- **trunk**: Main stem/trunk of tree, draw box around visible trunk\n",
    "- **canopy**: Leaves and branches, draw box around leaf clusters\n",
    "- **fruit**: Individual fruits or fruit clusters (grapes, tangerines)\n",
    "- **post**: Fence posts, poles, stakes (to distinguish from trunks!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 13: Train for second tree type (optional)\n",
    "# Run this if you want to train both vineyard AND tangerine\n",
    "\n",
    "TREE_TYPE_2 = \"tangerine\"  # Change to the other type\n",
    "\n",
    "if TREE_TYPE_2 == \"tangerine\":\n",
    "    CLASSES_2 = ['tangerine_trunk', 'tangerine_canopy', 'tangerine_fruit', 'post']\n",
    "else:\n",
    "    CLASSES_2 = ['vineyard_trunk', 'vineyard_canopy', 'grape_cluster', 'post']\n",
    "\n",
    "# Update paths and repeat training...\n",
    "print(f\"Ready to train for: {TREE_TYPE_2}\")\n",
    "print(f\"Update SOURCE_IMAGES and SOURCE_LABELS paths, then re-run cells 4B-12\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  },
  "accelerator": "GPU",
  "gpuClass": "standard"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
